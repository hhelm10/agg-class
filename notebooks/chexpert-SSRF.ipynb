{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "activated-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from graspologic.cluster import GaussianCluster as GMM\n",
    "\n",
    "from rsq.samplers import *\n",
    "from rsq.samplers import _Sampler\n",
    "from rsq.helpers import set_seeds\n",
    "\n",
    "from pulearn import BaggingPuClassifier\n",
    "from pulearn import ElkanotoPuClassifier\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def stratified_sample(y, p=0.67, replace=False):\n",
    "    unique_y, counts = np.unique(y, return_counts=True)\n",
    "    n_per_class = np.array([int(np.math.floor(p*c)) for c in counts])\n",
    "    n_per_class = np.array([max([npc, 1]) for npc in n_per_class])\n",
    "    \n",
    "    inds = [np.random.choice(np.where(y == unique_y[i])[0], size=npc, replace=replace) for i, npc in enumerate(n_per_class)]\n",
    "    \n",
    "    return np.concatenate(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "original-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSupervisedTreeClassifier(ClassifierMixin):\n",
    "    def __init__(self, max_depth=10, induce=True, \n",
    "                 induce_class=GMM, induce_kwargs={'min_components':100, 'max_components':100},\n",
    "                 random_projection=False,\n",
    "                 projection_kwargs={}):\n",
    "        \n",
    "        self.max_depth=max_depth\n",
    "        self.fitted=False\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.induce_class=induce_class\n",
    "        self.induce_kwargs=induce_kwargs\n",
    "        \n",
    "        self.random_projection=random_projection\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        self.projector=None\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "    \n",
    "        params_dict = {\"max_deth\": self.max_depth, \"fitted\": self.fitted, \n",
    "            'induce': self.induce, 'induce_class': self.induce_class, 'induce_kwargs':self.induce_kwargs,\n",
    "            'random_projection': self.random_projection, 'projection_kwargs': self.projection_kwargs,\n",
    "           }\n",
    "        return params_dict\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "        \n",
    "    def fit(self, X, y, y_induced=None):\n",
    "        self.classes_ = np.array([i for i in np.unique(y) if i != -1])\n",
    "        \n",
    "        if y_induced is None and self.induce:\n",
    "            if self.random_projection:\n",
    "                self.projector = GaussianRandomProjection(**self.projection_kwargs)\n",
    "                self.projector.fit(X)\n",
    "                X = self.projector.transform(X.copy())\n",
    "                \n",
    "            y_induced = self.induce_class(**self.induce_kwargs).fit_predict(X)\n",
    "            \n",
    "        self.tree = DecisionTreeClassifier(max_depth=self.max_depth).fit(X, y_induced)\n",
    "        decision_paths = self.tree.decision_path(X)\n",
    "        self.decision_paths = [dp.nonzero()[1] for dp in decision_paths]\n",
    "        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        self.labeled_decision_paths = [self.decision_paths[i] for i in labeled_indices]\n",
    "        \n",
    "        self.labels = y[labeled_indices]\n",
    "            \n",
    "        self.nodes_with_labeled_data = np.unique(np.concatenate(self.labeled_decision_paths))\n",
    "        self.projection_matrix = None\n",
    "        \n",
    "        self._get_mapping()\n",
    "        \n",
    "        self.fitted=True\n",
    "    \n",
    "    def _get_mapping(self):\n",
    "        self.mapping = {}\n",
    "                \n",
    "        for dp in self.decision_paths:\n",
    "            leaf_node = dp[-1]\n",
    "                            \n",
    "            if leaf_node in list(self.mapping.keys()):\n",
    "                continue\n",
    "            \n",
    "            for i in range(1, len(dp)+1):\n",
    "                temp_node = dp[-i]\n",
    "                \n",
    "                if temp_node in self.nodes_with_labeled_data:        \n",
    "                    temp_counts = np.zeros(len(self.classes_))\n",
    "\n",
    "                    tree_distance_to_labeled_data = np.zeros(len(self.labeled_decision_paths))\n",
    "                    for j, labeled_dp in enumerate(self.labeled_decision_paths):\n",
    "                        if temp_node in labeled_dp:\n",
    "                            tree_distance_to_labeled_data[j] = i + len(labeled_dp) - 1 - np.where(labeled_dp == temp_node)[0][0] - 1\n",
    "                        else:\n",
    "                            tree_distance_to_labeled_data[j] = 100\n",
    "                                                        \n",
    "                    min_tree_distance = np.min(tree_distance_to_labeled_data)\n",
    "                    argmins = np.where(tree_distance_to_labeled_data == min_tree_distance)[0]\n",
    "\n",
    "                    for index in argmins.astype(int):\n",
    "                        temp_counts[int(self.labels[index])] += 1\n",
    "                    \n",
    "                    self.mapping[leaf_node] = temp_counts / np.sum(temp_counts)\n",
    "                    break\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self.fitted:\n",
    "            raise ValueError('Not fitted')\n",
    "            \n",
    "        if self.random_projection:\n",
    "            X = self.projector.transform(X.copy())\n",
    "            \n",
    "        leaf_nodes = self.tree.apply(X)\n",
    "        posteriors = np.zeros((len(leaf_nodes), len(self.classes_)))\n",
    "        \n",
    "        for i, leaf_node in enumerate(leaf_nodes):\n",
    "            posteriors[i] = self.mapping[leaf_node]\n",
    "            \n",
    "        return posteriors\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "        \n",
    "class SSRF(ClassifierMixin):\n",
    "    def __init__(self, n_trees=100, supervised_max_depth=10, semi_supervised_max_depth=10, tree_split=None,\n",
    "                 induce=True, induce_class=GMM, induce_kwargs={'min_components':100, 'max_components':100},\n",
    "                 random_projection=False, projection_kwargs={}\n",
    "                ):\n",
    "        \n",
    "        self.n_trees=n_trees\n",
    "        self.sdepth=supervised_max_depth\n",
    "        self.ssdepth=semi_supervised_max_depth\n",
    "        self.tree_split = tree_split\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.induce_class=induce_class\n",
    "        self.induce_kwargs=induce_kwargs\n",
    "        \n",
    "        self.random_projection=random_projection\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        \n",
    "        self.forest = []\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "    \n",
    "        params_dict = {'n_trees': self.n_trees,\n",
    "            'supervised_max_depth': self.sdepth, 'semi_supervised_max_depth': self.ssdepth,\n",
    "            'tree_split': self.tree_split,\n",
    "            'induce': self.induce, 'induce_class': self.induce_class, 'induce_kwargs':self.induce_kwargs,\n",
    "            'random_projection': self.random_projection, 'projection_kwargs': self.projection_kwargs,\n",
    "           }\n",
    "        return params_dict\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "        \n",
    "    def _induce_labels(self, X):\n",
    "        return self.induce_class(**self.induce_kwargs).fit_predict(X)\n",
    "        \n",
    "    def fit(self, X, y, y_induced=None, n_cores=1):\n",
    "        self.classes_ = np.array([i for i in np.unique(y) if i != -1])\n",
    "        n = len(y)\n",
    "        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        \n",
    "        if self.tree_split is None:\n",
    "            self.tree_split = len(np.where(y != -1)[0]) / n\n",
    "                    \n",
    "        n_supervised_trees = int(self.n_trees * self.tree_split)\n",
    "        n_semi_supervised_trees = self.n_trees - n_supervised_trees\n",
    "        \n",
    "        condensed_func = lambda x: self._build_tree(X, y, y_induced, x, stratified=True)\n",
    "        func_tuples = np.concatenate((np.ones(n_supervised_trees), np.zeros(n_semi_supervised_trees))).astype(int)\n",
    "        \n",
    "        self.forest = Parallel(n_jobs=n_cores)(delayed(condensed_func)(tuple_) for tuple_ in func_tuples)\n",
    "                                \n",
    "    def predict_proba(self, X):\n",
    "        posteriors = np.zeros((X.shape[0], len(self.classes_)))\n",
    "                \n",
    "        for i, tree in enumerate(self.forest):\n",
    "            temp = tree.predict_proba(X)\n",
    "            posteriors += temp\n",
    "            \n",
    "        return posteriors / len(self.forest)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "            \n",
    "    def _build_tree(self, X, y, y_induced, supervised=True, stratified=True):        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        unlabeled_indices = np.where(y == -1)[0]\n",
    "        \n",
    "        if len(labeled_indices) == len(y):\n",
    "            all_supervised=True\n",
    "        else:\n",
    "            all_supervised=False\n",
    "            \n",
    "        if supervised:\n",
    "            bag_inds = stratified_sample(y[labeled_indices], p=0.67, replace=False)\n",
    "            tree = DecisionTreeClassifier(max_depth=self.sdepth)\n",
    "            tree.fit(X[labeled_indices[bag_inds]], y[labeled_indices[bag_inds]])\n",
    "            \n",
    "        else:\n",
    "            sbag_inds = stratified_sample(y[labeled_indices], p=0.67, replace=False)\n",
    "            if all_supervised:\n",
    "                bag_inds = sbag_inds\n",
    "            else:\n",
    "                ssbag_inds = np.random.choice(len(unlabeled_indices), size=int(X.shape[0]*0.67), replace=True)\n",
    "                bag_inds = np.concatenate((labeled_indices[sbag_inds], ssbag_inds))\n",
    "            \n",
    "            tree = SemiSupervisedTreeClassifier(max_depth=self.ssdepth, \n",
    "                                                induce=self.induce, induce_class=self.induce_class, induce_kwargs=self.induce_kwargs,\n",
    "                                               random_projection=self.random_projection, projection_kwargs=self.projection_kwargs)\n",
    "            if y_induced is None:\n",
    "                tree.fit(X[bag_inds], y[bag_inds])\n",
    "            else:\n",
    "                tree.fit(X[bag_inds], y[bag_inds], y_induced[bag_inds])\n",
    "                \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subjective-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../../../data/train_frontal_Bit_m-r101x1_with_labels.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "junior-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.array([vec for vec in data['vector']])\n",
    "\n",
    "# category_indices = np.array([6,8,10,11,12,13,14,15,16,17,18])\n",
    "category_indices = np.array([6,8,10,11,12,13,14,15,16,18])\n",
    "\n",
    "conditions = np.array(list(data.iloc[0, category_indices].keys()))\n",
    "\n",
    "competition_conditions = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "competition_conditions_indices = [np.where(conditions == c)[0][0] for c in conditions]\n",
    "\n",
    "\n",
    "labels = np.arange(len(category_indices))\n",
    "\n",
    "n, d = X_all.shape\n",
    "y_all = np.zeros(n)\n",
    "\n",
    "fly_list = []\n",
    "for i in range(n):\n",
    "    temp_conditions = data.iloc[i, category_indices]\n",
    "    positive_conditions = np.where(temp_conditions.values.astype(int) > 0)[0]\n",
    "    \n",
    "    if len(positive_conditions) > 1:\n",
    "        temp_competition_condition_indices = []\n",
    "        for pc in positive_conditions:\n",
    "            if pc in competition_conditions_indices:\n",
    "                temp_competition_condition_indices.append(pc)\n",
    "        if len(temp_competition_condition_indices) == 1:\n",
    "            y_all[i] = temp_competition_condition_indices[0]\n",
    "            fly_list.append(i)\n",
    "    elif len(positive_conditions) == 1:\n",
    "        y_all[i] = positive_conditions[0]\n",
    "        fly_list.append(i)\n",
    "        \n",
    "fly_list = np.array(fly_list)\n",
    "X = X_all[fly_list]\n",
    "y = y_all[fly_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "governmental-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16974 No Finding\n",
      "5591 Cardiomegaly\n",
      "2535 Lung Lesion\n",
      "13836 Edema\n",
      "3378 Consolidation\n",
      "1622 Pneumonia\n",
      "7590 Atelectasis\n",
      "7708 Pneumothorax\n",
      "27420 Pleural Effusion\n",
      "3079 Fracture\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_by_label = [np.where(y == c)[0] for c in np.unique(y)]\n",
    "\n",
    "[print(len(ibl), conditions[i]) for i, ibl in enumerate(idx_by_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "prop_labeled=[0, 0.1, 0.2, 0.5, 0.8, 1]\n",
    "n_cores=90\n",
    "n_mc=int(n_cores / len(prop_labeled))\n",
    "\n",
    "experiment_tuples = []\n",
    "\n",
    "for i, p in enumerate(prop_labeled):\n",
    "    for _ in range(n_mc):\n",
    "        all_inds = stratified_sample(y, p=0.1, replace=False)\n",
    "        n=len(all_inds)\n",
    "\n",
    "        inds_sup = stratified_sample(y[all_inds], p, replace=False)\n",
    "\n",
    "        X_ = X[all_inds]\n",
    "        y_ = -1 * np.ones(n)\n",
    "        y_[inds_sup] = y[all_inds[inds_sup]]\n",
    "\n",
    "        experiment_tuples.append((X_, y_))\n",
    "    \n",
    "\n",
    "condensed_func = lambda x: random_forest_exp(x[0], x[1])\n",
    "start_time = time()\n",
    "try:\n",
    "    accuracies = Parallel(n_jobs=n_cores)(delayed(condensed_func)(tupl) for tupl in experiment_tuples)\n",
    "    print(\"finished in %1.1f\"%(time() - start_time))\n",
    "except:\n",
    "    print(\"error after %1.1f\"%(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "exciting-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_exp(X, y, acorn=None, algorithm_indices=np.arange(4)):\n",
    "    accs = np.zeros(len(algorithm_indices))\n",
    "        \n",
    "    gmm=GMM(min_components=30, max_components=30)\n",
    "    gmm.fit(X)\n",
    "    y_induced = gmm.predict(X)\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    test_inds = np.where(y == -1)[0]\n",
    "    \n",
    "    if 0 in algorithm_indices:\n",
    "        urf = SSRF(n_trees=100, supervised_max_depth=None, semi_supervised_max_depth=None, tree_split=0)\n",
    "        urf.fit(X, y, y_induced)\n",
    "        accs[np.where(algorithm_indices == 0)[0][0]] = np.mean(urf.predict(X[test_inds]) == y[test_inds])\n",
    "\n",
    "    if 1 in algorithm_indices:\n",
    "        halfrf = SSRF(n_trees=100, supervised_max_depth=None, semi_supervised_max_depth=None, tree_split=0.5)\n",
    "        halfrf.fit(X, y, y_induced)\n",
    "        accs[np.where(algorithm_indices == 1)[0][0]] = np.mean(halfrf.predict(X[test_inds]) == y[test_inds])\n",
    "\n",
    "    if 2 in algorithm_indices:\n",
    "        ratiorf = SSRF(n_trees=100, supervised_max_depth=None, semi_supervised_max_depth=None, tree_split=None)\n",
    "        ratiorf.fit(X, y, y_induced)\n",
    "        accs[np.where(algorithm_indices == 2)[0][0]] = np.mean(ratiorf.predict(X[test_inds]) == y[test_inds])\n",
    "\n",
    "    if 3 in algorithm_indices:\n",
    "        rf = SSRF(n_trees=100, supervised_max_depth=None, semi_supervised_max_depth=None, tree_split=1)\n",
    "        rf.fit(X, y, y_induced)\n",
    "        accs[np.where(algorithm_indices == 3)[0][0]] = np.mean(rf.predict(X[test_inds]) == y[test_inds])\n",
    "    \n",
    "    if 4 in algorithm_indices:\n",
    "        randrf = SSRF(n_trees=100, supervised_max_depth=None, semi_supervised_max_depth=None, tree_split=0.5, \n",
    "                      induce=True, induce_class=GMM, induce_kwargs={'min_components': 30, 'max_components':30},\n",
    "                      random_projection=True, projection_kwargs={'n_components': 5})\n",
    "        randrf.fit(X, y, y_induced=None)\n",
    "        accs[np.where(algorithm_indices == 4)[0][0]] = np.mean(randrf.predict(X[test_inds]) == y[test_inds])\n",
    "        \n",
    "    \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "renewable-camping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-french",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APU",
   "language": "python",
   "name": "apu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
