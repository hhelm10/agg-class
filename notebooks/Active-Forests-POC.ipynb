{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medieval-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rsq import SSRF\n",
    "from rsq.samplers import _Sampler, ModelSampler\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from graspologic.cluster import GaussianCluster as GMM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import random_projection\n",
    "\n",
    "from scipy.stats import entropy\n",
    "  \n",
    "def semi_supervised_split(X, y, n_test, p_labeled=0.01):\n",
    "    n_all = len(y)\n",
    "    \n",
    "    n_available = n_all - n_test\n",
    "    p_available = n_available / n_all\n",
    "    \n",
    "    unique_y, counts = np.unique(y, return_counts=True)\n",
    "    priors = counts / np.sum(counts)\n",
    "    n_per_class = (n_available * priors).astype(int)\n",
    "    n_supervised_per_class = p_labeled * n_per_class\n",
    "    n_supervised_per_class = np.array([max([n_spc, 1]) for n_spc in n_supervised_per_class]).astype(int)\n",
    "    n_semisupervised_per_class = (n_per_class - n_supervised_per_class).astype(int)\n",
    "        \n",
    "    idx_by_label = [np.random.choice(np.where(y == c)[0], counts[i], replace=False) for i, c in enumerate(unique_y)]\n",
    "    supervised = [idx_by_label[i][:n_spc] for i, n_spc in enumerate(n_supervised_per_class)]\n",
    "    \n",
    "    supervised = np.concatenate(supervised, axis=0)\n",
    "    unsupervised = [idx_by_label[i][n_spc:n_semisupervised_per_class[i] + n_spc] \n",
    "                                     for (i, n_spc) in enumerate(n_supervised_per_class)]\n",
    "    unsupervised = np.concatenate(unsupervised)\n",
    "    \n",
    "    \n",
    "    test = np.array([i for i in range(n_all) if i not in supervised and i not in unsupervised])\n",
    "        \n",
    "    return supervised, unsupervised, test\n",
    "\n",
    "def stratified_sample(y, p=0.67, replace=False):\n",
    "    unique_y, counts = np.unique(y, return_counts=True)\n",
    "    n_per_class = np.array([int(np.math.floor(p*c)) for c in counts])\n",
    "    n_per_class = np.array([max([npc, 1]) for npc in n_per_class])\n",
    "    \n",
    "    inds = np.array([np.random.choice(np.where(y == unique_y[i])[0], size=npc, replace=replace) for i, npc in enumerate(n_per_class)])\n",
    "    \n",
    "    return np.concatenate(inds)\n",
    "\n",
    "# X = np.load('/home/hhelm/jataware/rsq2/output/feats/crow_resnet50/birdsnap/X.npy')\n",
    "# y = np.load('/home/hhelm/jataware/rsq2/output/feats/crow_resnet50/birdsnap/y.npy')\n",
    "\n",
    "# unique_y = np.unique(y)\n",
    "# y_map = {str_: i for (i,str_) in enumerate(unique_y)}\n",
    "# y = np.array([y_map[_] for _ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outstanding-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Helpers\n",
    "\n",
    "def subset(X, y, n):\n",
    "    if isinstance(X, list):\n",
    "        sel = np.random.choice(X[0].shape[0], n, replace=False)\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.choice(X.shape[0], n, replace=False)\n",
    "    \n",
    "    return X[sel], y[sel]\n",
    "\n",
    "def shuffle(X, y):\n",
    "    \"\"\" shuffle X and y \"\"\"\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        sel = np.random.permutation(X[0].shape[0])\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.permutation(X.shape[0])\n",
    "    return X[sel], y[sel]\n",
    "\n",
    "def adjust_prevalance(X, y, n_pos):\n",
    "    \"\"\" adjust the prevalance of the positive class \"\"\"\n",
    "    \n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    sel = np.hstack([\n",
    "        np.random.choice(pos_idx, n_pos, replace=False),\n",
    "        neg_idx,\n",
    "    ])\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.permutation(sel)\n",
    "    return X[sel], y[sel]\n",
    "\n",
    "\n",
    "def process_data(X, y, n_pos_labels, n_all):\n",
    "    X, y  = shuffle(X, y)\n",
    "\n",
    "    X = [normalize(x, axis=1, norm='l2') for x in X]\n",
    "\n",
    "    X, y = subset(X, y, n=n_all)\n",
    "\n",
    "    target = np.random.choice(np.unique(y)) # !! Uniform sample class, not according to prevalance\n",
    "    y      = (y == target).astype(np.int)\n",
    "\n",
    "    X, y = adjust_prevalance(X, y, n_pos_labels)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "\n",
    "def run_exp(X, y, model_idx, label_batchsize, n_label_rounds, n_queries, samplers):\n",
    "    qinds       = np.random.choice(np.where(y == 1)[0], size=n_queries, replace=False)\n",
    "    start_labs       = np.zeros(X[model_idx].shape[0]) - 1\n",
    "    start_labs[qinds] = 1\n",
    "    \n",
    "    prop_pos = np.zeros((len(samplers), n_label_rounds))\n",
    "    timer = np.zeros((len(samplers), n_label_rounds))\n",
    "    \n",
    "    for i, (sampler_name, sampler) in enumerate(samplers.items()):\n",
    "        t       = time()\n",
    "        if sampler_name == \"MIPSampler\":\n",
    "            sampler = sampler(fts=X, labels=start_labs.copy())\n",
    "        else:    \n",
    "            sampler = sampler(fts=X[model_idx], labels=start_labs.copy())\n",
    "        for j in range(n_label_rounds):\n",
    "\n",
    "            priority  = sampler.get_priority()            # get priority of unlabeled instances\n",
    "            next_idxs = priority[:label_batchsize]        # get next `query_bs` instances to label\n",
    "            next_labs = y[next_idxs]                      # get labels for next instances\n",
    "            sampler.set_label(next_idxs, next_labs)       # tell the sampler about the new labels\n",
    "            \n",
    "            prop_pos[i, j] = len(sampler.pos_idxs)\n",
    "            timer[i,j] = float(time() - t)\n",
    "        \n",
    "    return prop_pos, timer    \n",
    "            \n",
    "    \n",
    "def experiment(process_args, experiment_args):\n",
    "    X, y = process_data(*process_args)\n",
    "        \n",
    "    return run_exp(X, y, *experiment_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nonprofit-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MALF(_Sampler):\n",
    "    def __init__(self, fts, labels, \n",
    "                 n_trees_entropy=2, n_trees_labeledness=10,\n",
    "                 max_depth_entropy=2, max_depth_labeledness=10,\n",
    "                 tree_split_entropy=0.5, tree_split_labeledness=1,\n",
    "                 induce_entropy=True, induce_class_entropy=GMM, induce_kwargs_entropy={'min_components':100, 'max_components':100},\n",
    "                 induce_labeledness=True, induce_class_labeledness=GMM, induce_kwargs_labeledness={'min_components':100, 'max_components':100},\n",
    "                 random_projection_entropy=True, projection_kwargs_entropy={'n_components': 128},\n",
    "                 random_projection_labeledness=True, projection_kwargs_labeledness={'n_components': 128}\n",
    "                ):\n",
    "        self.fts      = fts\n",
    "        self.labels   = labels\n",
    "        \n",
    "        self.n_trees_entropy=n_trees_entropy\n",
    "        self.max_depth_entropy=max_depth_entropy\n",
    "        self.tree_split_entropy = tree_split_entropy\n",
    "        \n",
    "        self.induce_entropy=induce_entropy\n",
    "        self.induce_class_entropy=induce_class_entropy\n",
    "        self.induce_kwargs_entropy=induce_kwargs_entropy\n",
    "        \n",
    "        self.random_projection_entropy=random_projection_entropy\n",
    "        self.projection_kwargs_entropy=projection_kwargs_entropy\n",
    "        \n",
    "        self.entropy_forest = SSRF(self.n_trees_entropy, self.max_depth_entropy, self.tree_split_entropy, \n",
    "                                   self.induce_entropy, self.induce_class_entropy, self.induce_kwargs_entropy,\n",
    "                                  self.random_projection_entropy, self.projection_kwargs_entropy)\n",
    "        \n",
    "        \n",
    "        self.n_trees_labeledness=n_trees_labeledness\n",
    "        self.max_depth_labeledness=max_depth_labeledness\n",
    "        self.tree_split_labeledness=tree_split_labeledness\n",
    "        \n",
    "        self.induce_labeledness=induce_labeledness\n",
    "        self.induce_class_labeledness=induce_class_labeledness\n",
    "        self.induce_kwargs_labeledness=induce_kwargs_labeledness\n",
    "        \n",
    "        self.random_projection_labeledness=random_projection_labeledness\n",
    "        self.projection_kwargs_labeledness=projection_kwargs_labeledness\n",
    "        \n",
    "        self.labeledness_forest = SSRF(self.n_trees_labeledness, self.max_depth_labeledness, self.tree_split_labeledness, \n",
    "                                   self.induce_labeledness, self.induce_class_labeledness, self.induce_kwargs_labeledness,\n",
    "                                  self.random_projection_labeledness, self.projection_kwargs_labeledness)\n",
    "        \n",
    "        self.fitted=False\n",
    "        \n",
    "    def _fit_entropy(self, n_cores=-1):\n",
    "        self.entropy_forest.fit(self.fts, self.labels, None, n_cores)\n",
    "        \n",
    "    def _fit_labeledness(self, n_cores=-1):\n",
    "        temp_labels = np.zeros(len(self.labels))\n",
    "        temp_labels[np.where(self.labels != -1)[0]] = 1\n",
    "\n",
    "\n",
    "                \n",
    "        self.labeledness_forest.fit(self.fts, temp_labels, None, n_cores)\n",
    "\n",
    "        \n",
    "    def fit(self, n_cores=-1):\n",
    "        print(\"start timer\")\n",
    "        start_time = time()\n",
    "        self._fit_entropy(n_cores=n_cores)\n",
    "        print(\"fitted entropy\", time() - start_time)\n",
    "        int_time = time()\n",
    "        self._fit_labeledness(n_cores=n_cores)\n",
    "        print(\"fitted labeledness\", time() - int_time)\n",
    "        \n",
    "    def get_priority(self, n_cores=-1):\n",
    "        if not self.fitted:\n",
    "            self.fit(n_cores)\n",
    "            \n",
    "        pos_idxs = self.pos_idxs\n",
    "        neg_idxs = self.neg_idxs\n",
    "        mis_idxs = self.mis_idxs\n",
    "                    \n",
    "        posteriors_entropy = self.entropy_forest.predict_proba(self.fts[mis_idxs])\n",
    "        entropy_score = entropy(posteriors_entropy, axis=0)\n",
    "        \n",
    "        posteriors_labeledness = self.labeledness_forest.predict_proba(self.fts[mis_idxs])\n",
    "        \n",
    "        print(entropy_score.shape, posteriors_labeledness.shape)\n",
    "        \n",
    "        scores = np.multiply(entropy_score, posteriors_labeledness[:, 1])\n",
    "        \n",
    "        mis_ranks = mis_idxs[np.argsort(scores)]\n",
    "        \n",
    "        return mis_ranks\n",
    "        \n",
    "    \n",
    "    def set_label(self, indices, labels):  \n",
    "        pos_idxs = self.pos_idxs\n",
    "        for idx, yy in zip(indices, labels):\n",
    "            self.labels[idx] = yy\n",
    "            \n",
    "            assert yy in [0, 1]\n",
    "                        \n",
    "            if yy == 1:\n",
    "                self.labels[idx] = 1\n",
    "            else:\n",
    "                self.labels[idx] = 0\n",
    "                            \n",
    "        self.update_posteriors(indices)\n",
    "    \n",
    "    def update_posteriors(self, indices):\n",
    "        # can parallelize\n",
    "        for tree in self.entropy_forest.forest:\n",
    "            new_labeled_decision_paths = [tree.decision_paths[_] for _ in indices]\n",
    "            nodes_with_new_labeled_data = np.unique(np.concatenate(new_labeled_decision_paths))\n",
    "            \n",
    "            updated_leaf_nodes = []\n",
    "\n",
    "            for dp in tree.decision_paths:\n",
    "                leaf_node = dp[-1]\n",
    "                temp_intersection=set(nodes_with_new_labeled_data).intersection(set(dp))\n",
    "                if len(temp_intersection) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if leaf_node in updated_leaf_nodes:\n",
    "                    continue\n",
    "\n",
    "                for i in range(1, len(dp)+1):\n",
    "                    temp_node = dp[-i]\n",
    "\n",
    "                    if temp_node in nodes_with_new_labeled_data:        \n",
    "                        temp_counts = np.zeros(len(tree.classes))\n",
    "\n",
    "                        tree_distance_to_labeled_data = np.zeros(len(tree.labeled_decision_paths) + len(indices))\n",
    "                        for j, labeled_dp in enumerate(np.concatenate((tree.labeled_decision_paths, new_labeled_decision_paths))):\n",
    "                            if temp_node in labeled_dp:\n",
    "                                tree_distance_to_labeled_data[j] = i + len(labeled_dp) - 1 - np.where(labeled_dp == temp_node)[0][0] - 1\n",
    "                            else:\n",
    "                                tree_distance_to_labeled_data[j] = 100\n",
    "\n",
    "                        min_tree_distance = np.min(tree_distance_to_labeled_data)\n",
    "                        argmins = np.where(tree_distance_to_labeled_data == min_tree_distance)[0]\n",
    "\n",
    "                        for index in argmins.astype(int):\n",
    "                            temp_counts[int(self.labels[index])] += 1\n",
    "\n",
    "                        tree.mapping[leaf_node] = temp_counts / np.sum(temp_counts)\n",
    "                        break\n",
    "            tree.labeled_decision_paths = np.concatenate((tree.labeled_decision_paths, new_labeled_decision_paths))\n",
    "            tree.nodes_with_labeled_data = np.unique(np.concatenate((tree.nodes_with_labeled_data, nodes_with_new_labeled_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "infinite-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Experiment parameters & initial data loading\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "data_files = ['../output/feats/crow_resnet50/birdsnap/',\n",
    "#               '../output/feats/crow_wide_resnet101_2/birdsnap/',\n",
    "#               '../output/feats/crow_resnext101_32x8d/birdsnap/',\n",
    "#               '../output/feats/crow_vgg19/birdsnap/'\n",
    "             ]\n",
    "models = [s.split('/')[-3] for s in data_files]\n",
    "\n",
    "\n",
    "X = [np.load(os.path.join(f, 'X.npy')).astype(np.float64) for f in data_files]\n",
    "y = np.load(os.path.join(data_files[0], 'y.npy'))\n",
    "n_pos_labels=3\n",
    "n_all=5000\n",
    "\n",
    "label_batchsize=1\n",
    "n_label_rounds=100\n",
    "n_queries=1\n",
    "samplers = {\n",
    "#     \"MIPSampler\"        : partial(MIPSampler, initial_max_seconds=60, update_max_seconds=30, warm_start='barycenter'),\n",
    "    \"MALForestSampler\"  : MALF,\n",
    "    \"SVCSampler\"        : partial(ModelSampler, model='svc'),\n",
    "#     \"LogisticSampler\"   : partial(ModelSampler, model='logistic'),\n",
    "    \n",
    "#     \"LASSampler\"        : LASSampler,\n",
    "    \n",
    "#     \"NaiveMeanSampler\"  : partial(PoolingSampler, pool_fn='mean', score_fn='pos'),\n",
    "#     \"RatioMeanSampler\"  : partial(PoolingSampler, pool_fn='mean'),\n",
    "#     \"RatioMaxSampler\"   : partial(PoolingSampler, pool_fn='max'),\n",
    "#     \"GEMSampler1\"       : partial(PoolingSampler, pool_fn='gem', gem_p=1),\n",
    "#     \"GEMSampler4\"       : partial(PoolingSampler, pool_fn='gem', gem_p=4),\n",
    "#     \"GEMSampler16\"      : partial(PoolingSampler, pool_fn='gem', gem_p=16)\n",
    "}\n",
    "\n",
    "experiment_args = (label_batchsize, n_label_rounds, n_queries, samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "broke-vancouver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start timer\n",
      "fitting forest\n",
      "building forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/hhelm/venvs/apu/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/hhelm/venvs/apu/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/hhelm/venvs/apu/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/hhelm/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/hhelm/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-32-f77c9c720a7b>\", line 36, in <lambda>\n  File \"<ipython-input-32-f77c9c720a7b>\", line 90, in _build_tree\n  File \"<ipython-input-33-c1b2e3a89ef3>\", line 41, in fit\n  File \"<ipython-input-33-c1b2e3a89ef3>\", line 71, in _get_mapping\nIndexError: index 1 is out of bounds for axis 0 with size 1\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7bff9ded5911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcondensed_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprops_and_timers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtemp_props\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops_and_timers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (n_mc, len(samplers), n_label_rounds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtemp_timers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops_and_timers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7bff9ded5911>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mexperiment_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_label_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcondensed_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprops_and_timers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-23ec55a2ff64>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(process_args, experiment_args)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprocess_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexperiment_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-23ec55a2ff64>\u001b[0m in \u001b[0;36mrun_exp\u001b[0;34m(X, y, model_idx, label_batchsize, n_label_rounds, n_queries, samplers)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_label_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mpriority\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_priority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# get priority of unlabeled instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mnext_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriority\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_batchsize\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# get next `query_bs` instances to label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnext_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_idxs\u001b[0m\u001b[0;34m]\u001b[0m                      \u001b[0;31m# get labels for next instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-432ea197b663>\u001b[0m in \u001b[0;36mget_priority\u001b[0;34m(self, n_cores)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_priority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mpos_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_idxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-432ea197b663>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_cores)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start timer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fitted entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mint_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-432ea197b663>\u001b[0m in \u001b[0;36m_fit_entropy\u001b[0;34m(self, n_cores)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_labeledness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f77c9c720a7b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, y_induced, n_cores)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"building forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtuple_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "n_cores=30\n",
    "n_mc=1\n",
    "\n",
    "prop_pos_1 = np.zeros((len(models), len(samplers), n_mc, n_label_rounds))\n",
    "timer_1 = np.zeros((len(models), len(samplers), n_mc, n_label_rounds))\n",
    "\n",
    "for i, XX in enumerate(tqdm(X)):\n",
    "    process_args = (X, y, n_pos_labels, n_all)\n",
    "    \n",
    "    samplers_ = samplers.copy()\n",
    "    if i > 0:\n",
    "        samplers_.pop('MIPSampler')\n",
    "\n",
    "    experiment_args = (i, label_batchsize, n_label_rounds, n_queries, samplers_)\n",
    "    \n",
    "    condensed_experiment = lambda x: experiment(process_args, experiment_args)\n",
    "    \n",
    "    props_and_timers = Parallel(n_jobs=1)(delayed(condensed_experiment)(_) for _ in np.zeros(1))\n",
    "    temp_props = np.array([p for (p, t) in props_and_timers]) # (n_mc, len(samplers), n_label_rounds)\n",
    "    temp_timers = np.array([t for (p, t) in props_and_timers])\n",
    "    \n",
    "    prop_pos_1[i] = temp_props.transpose((1,0,2))\n",
    "    timer_1[i] = temp_props.transpose((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "passive-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRF:\n",
    "    def __init__(self, n_trees=100, max_depth=10, tree_split=None,\n",
    "                 induce=True, induce_class=GMM, induce_kwargs={'min_components':10, 'max_components':10},\n",
    "                 random_projection=False, projection_kwargs={}\n",
    "                ):\n",
    "        \n",
    "        self.n_trees=n_trees\n",
    "        self.max_depth=max_depth\n",
    "        self.tree_split = tree_split\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.induce_class=induce_class\n",
    "        self.induce_kwargs=induce_kwargs\n",
    "        \n",
    "        self.random_projection=random_projection\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        \n",
    "        self.forest = []\n",
    "        \n",
    "    def induce_labels(self, X, GMM_kwargs={'min_clusters': 10, 'max_clusters': 20, 'covariance':'tied'}):\n",
    "        self.induced_labels = GMM(**GMM_kwargs).fit_predict(X)\n",
    "        \n",
    "    def fit(self, X, y, y_induced, n_cores=-1):\n",
    "        print(\"fitting forest\")\n",
    "        self.classes = np.array([i for i in np.unique(y) if i != -1])\n",
    "        n = len(y)\n",
    "        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        \n",
    "        if self.tree_split is None:\n",
    "            self.tree_split = len(np.where(y != -1)[0]) / n\n",
    "                    \n",
    "        n_supervised_trees = int(self.n_trees * self.tree_split)\n",
    "        n_semi_supervised_trees = self.n_trees - n_supervised_trees\n",
    "        \n",
    "        condensed_func = lambda x: self._build_tree(X, y, y_induced, x, stratified=True)\n",
    "        func_tuples = np.concatenate((np.ones(n_supervised_trees), np.zeros(n_semi_supervised_trees))).astype(int)\n",
    "        \n",
    "        print(\"building forest\")\n",
    "        self.forest = Parallel(n_jobs=n_cores)(delayed(condensed_func)(tuple_) for tuple_ in func_tuples)\n",
    "                                \n",
    "    def predict_proba(self, X):\n",
    "        posteriors = np.zeros((X.shape[0], len(self.classes)))\n",
    "                \n",
    "        for i, tree in enumerate(self.forest):\n",
    "            temp = tree.predict_proba(X)\n",
    "            posteriors += temp\n",
    "            \n",
    "        return posteriors / len(self.forest)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "            \n",
    "    def _build_tree(self, X, y, y_induced, supervised=True, stratified=True):\n",
    "        def worker(tree, X, y, y_induced=None):\n",
    "            if y_induced is None:\n",
    "                tree.fit(X, y)\n",
    "            else:\n",
    "                tree.fit(X, y, y_induced)\n",
    "            return tree\n",
    "        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        unlabeled_indices = np.where(y == -1)[0]\n",
    "        \n",
    "        print(supervised, X.shape, len(y))\n",
    "        \n",
    "        if len(labeled_indices) == len(y):\n",
    "            all_supervised=True\n",
    "        else:\n",
    "            all_supervised=False\n",
    "            \n",
    "        if supervised:\n",
    "            bag_inds = stratified_sample(y[labeled_indices], p=0.67, replace=False)\n",
    "            tree = Tree(max_depth=self.max_depth)\n",
    "            tree.fit(X[labeled_indices[bag_inds]], y[labeled_indices[bag_inds]])\n",
    "            \n",
    "        else:\n",
    "            sbag_inds = stratified_sample(y[labeled_indices], p=0.67, replace=False)\n",
    "            if all_supervised:\n",
    "                bag_inds = sbag_inds\n",
    "            else:\n",
    "                ssbag_inds = np.random.choice(len(unlabeled_indices), size=int(X.shape[0]*0.67), replace=True)\n",
    "                bag_inds = np.concatenate((labeled_indices[sbag_inds], ssbag_inds))\n",
    "            \n",
    "            tree = SemiSupervisedTreeClassifier(max_depth=self.max_depth, \n",
    "                                                induce=self.induce, induce_class=self.induce_class, induce_kwargs=self.induce_kwargs,\n",
    "                                               random_projection=self.random_projection, projection_kwargs=self.projection_kwargs)\n",
    "            if y_induced is None:\n",
    "                tree.fit(X[bag_inds], y[bag_inds])\n",
    "            else:\n",
    "                tree.fit(X[bag_inds], y[bag_inds], y_induced[bag_inds])\n",
    "                \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fresh-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSupervisedTreeClassifier:\n",
    "    def __init__(self, max_depth=10, induce=True, \n",
    "                 induce_class=GMM, induce_kwargs={'min_components':100, 'max_components':100},\n",
    "                 random_projection=False,\n",
    "                 projection_kwargs={}):\n",
    "        \n",
    "        self.max_depth=max_depth\n",
    "        self.fitted=False\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.induce_class=induce_class\n",
    "        self.induce_kwargs=induce_kwargs\n",
    "        \n",
    "        self.random_projection=random_projection\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        self.projector=None\n",
    "        \n",
    "    def fit(self, X, y, y_induced=None):\n",
    "        self.classes = np.array([i for i in np.unique(y) if i != -1])\n",
    "        \n",
    "        if y_induced is None and self.induce:\n",
    "            if self.random_projection:\n",
    "                self.projector = random_projection.GaussianRandomProjection(**self.projection_kwargs)\n",
    "                self.projector.fit(X)\n",
    "                X = self.projector.transform(X.copy())\n",
    "                \n",
    "            y_induced = self.induce_class(**self.induce_kwargs).fit_predict(X)\n",
    "            \n",
    "        self.tree = Tree(max_depth=self.max_depth).fit(X, y_induced)\n",
    "        decision_paths = self.tree.decision_path(X)\n",
    "        self.decision_paths = [dp.nonzero()[1] for dp in decision_paths]\n",
    "        \n",
    "        labeled_indices = np.where(y != -1)[0]\n",
    "        self.labeled_decision_paths = [self.decision_paths[i] for i in labeled_indices]\n",
    "        \n",
    "        self.labels = y[labeled_indices]\n",
    "            \n",
    "        self.nodes_with_labeled_data = np.unique(np.concatenate(self.labeled_decision_paths))\n",
    "        self.projection_matrix = None\n",
    "        \n",
    "        self._get_mapping()\n",
    "        \n",
    "        self.fitted=True\n",
    "    \n",
    "    def _get_mapping(self):\n",
    "        self.mapping = {}\n",
    "                \n",
    "        for dp in self.decision_paths:\n",
    "            leaf_node = dp[-1]\n",
    "                            \n",
    "            if leaf_node in list(self.mapping.keys()):\n",
    "                continue\n",
    "            \n",
    "            for i in range(1, len(dp)+1):\n",
    "                temp_node = dp[-i]\n",
    "                \n",
    "                if temp_node in self.nodes_with_labeled_data:        \n",
    "                    temp_counts = np.zeros(len(self.classes))\n",
    "\n",
    "                    tree_distance_to_labeled_data = np.zeros(len(self.labeled_decision_paths))\n",
    "                    for j, labeled_dp in enumerate(self.labeled_decision_paths):\n",
    "                        if temp_node in labeled_dp:\n",
    "                            tree_distance_to_labeled_data[j] = i + len(labeled_dp) - 1 - np.where(labeled_dp == temp_node)[0][0] - 1\n",
    "                        else:\n",
    "                            tree_distance_to_labeled_data[j] = 100\n",
    "                                                        \n",
    "                    min_tree_distance = np.min(tree_distance_to_labeled_data)\n",
    "                    argmins = np.where(tree_distance_to_labeled_data == min_tree_distance)[0]\n",
    "\n",
    "                    for index in argmins.astype(int):\n",
    "                        temp_counts[int(self.labels[index])] += 1\n",
    "                    \n",
    "                    self.mapping[leaf_node] = temp_counts / np.sum(temp_counts)\n",
    "                    break\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self.fitted:\n",
    "            raise ValueError('Not fitted')\n",
    "            \n",
    "        if self.random_projection:\n",
    "            X = self.projector.transform(X.copy())\n",
    "            \n",
    "        leaf_nodes = self.tree.apply(X)\n",
    "        posteriors = np.zeros((len(leaf_nodes), len(self.classes)))\n",
    "        \n",
    "        for i, leaf_node in enumerate(leaf_nodes):\n",
    "            posteriors[i] = self.mapping[leaf_node]\n",
    "            \n",
    "        return posteriors\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-framing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APU",
   "language": "python",
   "name": "apu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
