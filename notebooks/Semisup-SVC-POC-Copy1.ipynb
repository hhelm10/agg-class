{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prepared-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import numba\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# from rsq import SVCEnsemble\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def stratified_sample(y, p=0.67, replace=False):\n",
    "    unique_y, counts = np.unique(y, return_counts=True)\n",
    "    n_per_class = np.array([int(np.math.floor(p*c)) for c in counts])\n",
    "    n_per_class = np.array([max([npc, 1]) for npc in n_per_class])\n",
    "    \n",
    "    inds = np.array([np.random.choice(np.where(y == unique_y[i])[0], size=npc, replace=replace) for i, npc in enumerate(n_per_class)])\n",
    "    \n",
    "    return np.concatenate(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "passive-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thundersvm import SVC as tSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "increased-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionSVC(SVC):\n",
    "    def __init__(self, projector='gaussian', projection_kwargs={},\n",
    "                 classes=None,\n",
    "                 thunder=True,\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        if projector == 'gaussian':\n",
    "            self.projector = GaussianRandomProjection\n",
    "        else:\n",
    "            self.projector=projector\n",
    "\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        self.classes_=classes\n",
    "        \n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        \n",
    "        self.thunder=thunder\n",
    "                \n",
    "        super().__init__(C, kernel, degree, gamma, \n",
    "                 coef0, shrinking, probability,\n",
    "                 tol, cache_size, class_weight, verbose, \n",
    "                 max_iter, decision_function_shape, break_ties, random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "        if -1 in self.classes_:\n",
    "            self.classes_ = self.classes_[1:]\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if self.thunder:\n",
    "            self.svc = OneVsRestClassifier(tSVC(kernel=self.kernel, C=self.C))\n",
    "        else:\n",
    "            self.svc = SVC(kernel=self.kernel, C=self.C)\n",
    "        \n",
    "        if self.projector is not None:\n",
    "            self.projector = self.projector(**self.projection_kwargs)\n",
    "            self.projector.fit(X)\n",
    "            self.svc.fit(self.projector.transform(X), y)\n",
    "        else:\n",
    "            self.svc.fit(X, y)\n",
    "        \n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        if self.projector is not None:\n",
    "            dfs = self.svc.decision_function(self.projector.transform(X))\n",
    "        else:\n",
    "            dfs = self.svc.decision_function(X)\n",
    "            \n",
    "        return dfs\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.projector is None:\n",
    "            return self.classes_[np.argmax(self.decision_function(X), axis=-1)]\n",
    "        else:\n",
    "            return self.classes_[np.argmax(self.decision_function(self.projector.transform(X)), axis=-1)]\n",
    "        \n",
    "        \n",
    "class SemiSupervisedSVC(ProjectionSVC):\n",
    "    def __init__(self, projector=None, projection_kwargs={}, \n",
    "                 classes=None, \n",
    "                 thunder=True,\n",
    "                 cluster_class='gmm', cluster_kwargs={'n_components':-2, 'covariance_type':'spherical'},\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        if cluster_class == 'gmm':\n",
    "            self.cluster_class = GaussianMixture\n",
    "        elif cluster_class == 'kmeans':\n",
    "            self.cluster_class = KMeans\n",
    "        else:\n",
    "            self.cluster_class=cluster_class\n",
    "            \n",
    "        self.cluster_kwargs=cluster_kwargs\n",
    "        \n",
    "        super().__init__(projector, projection_kwargs, classes, thunder, C, kernel, degree, gamma, \n",
    "                 coef0, shrinking, probability,\n",
    "                 tol, cache_size, class_weight, verbose, \n",
    "                 max_iter, decision_function_shape, break_ties, random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, y_induced=None):\n",
    "        self.unlabeled_inds = np.where(y == -1)[0].astype(int)\n",
    "        self.labeled_inds = np.where(y != -1)[0].astype(int)\n",
    "        \n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "            if -1 in self.classes_:\n",
    "                self.classes_ = self.classes_[1:]\n",
    "\n",
    "        \n",
    "        n_classes = len(self.classes_)\n",
    "        labeled_inds = np.where(y != 1)[0]\n",
    "        \n",
    "        if y_induced is None:\n",
    "            if 'n_components' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_components'] < 0:\n",
    "                    self.cluster_kwargs['n_components'] *= -1\n",
    "                    self.cluster_kwargs['n_components'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_components'] = int(self.cluster_kwargs['n_components'])\n",
    "                self.n_components=self.cluster_kwargs['n_components']\n",
    "            elif 'n_clusters' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_clusters'] < 0:\n",
    "                    self.cluster_kwargs['n_clusters'] *= -1\n",
    "                    self.cluster_kwargs['n_clusters'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_clusters'] = int(self.cluster_kwargs['n_clusters'])\n",
    "                self.n_components=self.cluster_kwargs['n_clusters']\n",
    "            else:\n",
    "                raise ValueError('keyword n_components or n_clusters must be present in cluster_kwargs')\n",
    "        else:\n",
    "            self.n_components = len(np.unique(y_induced))\n",
    "            \n",
    "                \n",
    "        if y_induced is None:\n",
    "            cluster_instance = self.cluster_class(**self.cluster_kwargs)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            if y_induced is None:\n",
    "                y_induced = cluster_instance.fit_predict(X)\n",
    "        else:\n",
    "            self.projector = self.projector(**self.projection_kwargs) \n",
    "            self.projector.fit(X)\n",
    "            if y_induced is None:\n",
    "                y_induced = cluster_instance.fit_predict(self.projector.transform(X))\n",
    "         \n",
    "        self.labels_per_cluster = np.zeros((self.n_components, n_classes))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            inds = np.where(y == self.classes_[i])\n",
    "            temp_y_induced = y_induced[inds]\n",
    "            temp_counts = np.array([len(np.where(temp_y_induced == c)[0]) for c in range(self.n_components)])\n",
    "            \n",
    "            self.labels_per_cluster[:, i] = temp_counts\n",
    " \n",
    "        self.svc = SVC(kernel=self.kernel, C=self.C)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            self.svc.fit(X, y_induced)\n",
    "        else:\n",
    "            self.svc.fit(self.projector.transform(X), y_induced)\n",
    "    \n",
    "\n",
    "    def decision_function(self, X):\n",
    "        n_labeled = np.sum(self.labels_per_cluster)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            dfs = self.svc.decision_function(X)\n",
    "        else:\n",
    "            dfs = self.svc.decision_function(self.projector.transform(X))\n",
    "            \n",
    "        return dfs @ self.labels_per_cluster\n",
    "            \n",
    "\n",
    "class SVCEnsemble(SVC):\n",
    "    def __init__(self, n_sup=1, n_semisup=1, sup_weight=None, \n",
    "                 p_inbag=1, \n",
    "                 projector=None, projection_kwargs={},\n",
    "                 classes=None, n_jobs=1,\n",
    "                 thunder=False, \n",
    "                 induce=0, cluster_class='gmm', cluster_kwargs={'n_components':-2, 'covariance_type':'spherical'},\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.n_sup=n_sup\n",
    "        self.n_semisup = n_semisup\n",
    "        self.sup_weight=sup_weight\n",
    "\n",
    "        self.p_inbag=p_inbag\n",
    "        \n",
    "        self.classes_ = classes\n",
    "        self.n_jobs=n_jobs\n",
    "        \n",
    "        if projector is \"gaussian\":\n",
    "            self.projector=GaussianRandomProjection\n",
    "        else:\n",
    "            self.projector=projector\n",
    "\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        \n",
    "        if cluster_class == 'gmm':\n",
    "            self.cluster_class = GaussianMixture\n",
    "        elif cluster_class == 'kmeans':\n",
    "            self.cluster_class = KMeans\n",
    "            \n",
    "        self.cluster_kwargs=cluster_kwargs\n",
    "        \n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        \n",
    "        self.thunder=True\n",
    "            \n",
    "        self.ensemble = []\n",
    "        \n",
    "        super().__init__(C, kernel, degree, gamma, \n",
    "                 coef0, shrinking, probability,\n",
    "                 tol, cache_size, class_weight, verbose, \n",
    "                 max_iter, decision_function_shape, break_ties, random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.unlabeled_inds = np.where(y == -1)[0].astype(int)\n",
    "        self.labeled_inds = np.where(y != -1)[0].astype(int)\n",
    "        \n",
    "        if self.sup_weight is None:\n",
    "            self.sup_weight = len(self.labeled_inds) / (len(self.labeled_inds) + len(self.unlabeled_inds))\n",
    "        \n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "            if -1 in self.classes_:\n",
    "                self.classes_ = self.classes_[1:]\n",
    "                \n",
    "        if self.induce > 0:\n",
    "            if 'n_components' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_components'] < 0:\n",
    "                    self.cluster_kwargs['n_components'] *= -1\n",
    "                    self.cluster_kwargs['n_components'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_components'] = int(self.cluster_kwargs['n_components'])\n",
    "                self.n_components=self.cluster_kwargs['n_components']\n",
    "            elif 'n_clusters' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_clusters'] < 0:\n",
    "                    self.cluster_kwargs['n_clusters'] *= -1\n",
    "                    self.cluster_kwargs['n_clusters'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_clusters'] = int(self.cluster_kwargs['n_clusters'])\n",
    "                self.n_components=self.cluster_kwargs['n_clusters']\n",
    "            else:\n",
    "                raise ValueError('keyword n_components must be present in cluster_kwargs')\n",
    "            \n",
    "            cluster_instance = self.cluster_class(**self.cluster_kwargs)\n",
    "            self.y_induced=cluster_instance.fit_predict(X)\n",
    "                        \n",
    "        condensed_func = lambda x: self._train_svc(X, y, x, stratified=True)\n",
    "        func_tuples = np.concatenate((np.ones(self.n_sup), np.zeros(self.n_semisup))).astype(int)\n",
    "        \n",
    "        self.ensemble = Parallel(n_jobs=self.n_jobs)(delayed(condensed_func)(tuple_) for tuple_ in func_tuples)\n",
    "            \n",
    "    def _train_svc(self, X, y, supervised=True, stratified=True):                \n",
    "        if len(self.labeled_inds) == len(y):\n",
    "            all_supervised=True\n",
    "        else:\n",
    "            all_supervised=False\n",
    "\n",
    "        if self.p_inbag >= 1:\n",
    "            self.p_inbag=1\n",
    "            replace=False\n",
    "        else:\n",
    "            replace=True\n",
    "            \n",
    "        if supervised:\n",
    "            bag_inds = stratified_sample(y[self.labeled_inds], p=self.p_inbag, replace=False)\n",
    "            svc = ProjectionSVC(projector=self.projector, projection_kwargs=self.projection_kwargs, \n",
    "                                thunder=self.thunder, classes=self.classes_, kernel=self.kernel, C=self.C)\n",
    "            svc.fit(X[self.labeled_inds[bag_inds]], y[self.labeled_inds[bag_inds]])\n",
    "            \n",
    "        else:\n",
    "            sbag_inds = stratified_sample(y[self.labeled_inds], p=self.p_inbag, replace=False)\n",
    "            if all_supervised:\n",
    "                bag_inds = sbag_inds\n",
    "            else:\n",
    "                ssbag_inds = np.random.choice(len(self.unlabeled_inds), size=int(X.shape[0]*0.67), replace=True)\n",
    "                bag_inds = np.concatenate((self.labeled_inds[sbag_inds], ssbag_inds))\n",
    "            \n",
    "            svc = SemiSupervisedSVC(projector=self.projector, projection_kwargs=self.projection_kwargs, \n",
    "                                    classes=self.classes_,\n",
    "                                    thunder=self.thunder,\n",
    "                                   cluster_class=self.cluster_class, cluster_kwargs=self.cluster_kwargs,\n",
    "                                    kernel=self.kernel, C=self.C)\n",
    "\n",
    "            use_pre_induced=np.random.binomial(1, self.induce)\n",
    "            if use_pre_induced:\n",
    "                svc.fit(X[bag_inds], y[bag_inds], self.y_induced[bag_inds])\n",
    "            else:\n",
    "                svc.fit(X[bag_inds], y[bag_inds])\n",
    "                    \n",
    "                \n",
    "        return svc\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        if self.n_sup > 0:\n",
    "            sup_dfs = np.sum([svc.decision_function(X) for svc in self.ensemble[:self.n_sup]], axis=0)\n",
    "            \n",
    "            sup_dfs /= np.sqrt((sup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "        else:\n",
    "            sup_dfs = 0\n",
    "        \n",
    "\n",
    "        if self.n_semisup > 0:    \n",
    "            semisup_dfs = np.sum([svc.decision_function(X) for svc in self.ensemble[self.n_sup:]], axis=0)\n",
    "            semisup_dfs /= np.sqrt((semisup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "        else:\n",
    "            semisup_dfs = 0\n",
    "\n",
    "        return (self.sup_weight * sup_dfs) + ((1 - self.sup_weight) * semisup_dfs)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.decision_function(X)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.decision_function(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "sharp-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_gaussians(n, d, n_classes=2, type2_var=0.5, var=1, n_labels_per_class=1, n_test=100, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "                \n",
    "    means = np.random.multivariate_normal(np.zeros(d), type2_var * np.eye(d), size=int(n_classes))\n",
    "            \n",
    "    data = np.concatenate([np.random.multivariate_normal(mean, var*np.eye(d), size=n) for mean in means])\n",
    "    latent_labels = np.concatenate([i*np.ones(n) for i in range(n_classes)])\n",
    "    \n",
    "    data_test = np.concatenate([np.random.multivariate_normal(mean, var*np.eye(d), size=n_test) for mean in means])\n",
    "    y_test = np.concatenate([i*np.ones(n_test) for i in range(n_classes)])\n",
    "    \n",
    "    shuf = np.random.choice(n_classes*n, n_classes*n, replace=False)\n",
    "    data, latent_labels = data[shuf], latent_labels[shuf]\n",
    "    \n",
    "    known_labels = -1 * np.ones(n_classes*n)\n",
    "    labeled_inds = [np.where(latent_labels == i)[0][:n_labels_per_class] for i in range(n_classes)]\n",
    "    \n",
    "    for i, inds in enumerate(labeled_inds):\n",
    "        known_labels[inds] = i\n",
    "                \n",
    "    return data, known_labels, latent_labels, data_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cooked-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_exp(n=1000, d=10, n_classes=10, cc=0.5, c=0.75, n_labels_per_class=50, acorn=None, algorithm_indices=np.arange(4)):\n",
    "    accs = np.zeros(len(algorithm_indices))\n",
    "    \n",
    "    X, y, y_true, X_test, y_test = few_shot_gaussians(n, d, n_classes, cc, c, int(n*p), 100, acorn)\n",
    "    \n",
    "    inds_sup = np.where(y != -1)[0].astype(int)\n",
    "    inds_unsup = np.array([i for i in range(len(y)) if i not in inds_sup])\n",
    "\n",
    "    y_ = -1 * np.ones(int(n*n_classes))\n",
    "    \n",
    "    y_[inds_sup] = y[inds_sup]\n",
    "    \n",
    "    classes = np.arange(n_classes)\n",
    "    \n",
    "    #-\n",
    "    accs = np.zeros(6)\n",
    "    times = np.zeros(6)\n",
    "            \n",
    "    time_ = time.time()\n",
    "    \n",
    "                                                                            \n",
    "    #- GMM, 0.5*n_classes\n",
    "    svc_semisup_ensemble6 = SVCEnsemble(n_sup=200, n_semisup=200, p_inbag=0.67,\n",
    "                                        projection_kwargs={'n_components': 8}, \n",
    "                                        induce=0,\n",
    "                                        cluster_class='gmm', cluster_kwargs={'n_components': -2},\n",
    "                                        kernel='linear',\n",
    "                                        thunder=True,\n",
    "                                        classes=classes)\n",
    "    svc_semisup_ensemble6.fit(X, y)\n",
    "    accs[0] = (svc_semisup_ensemble6.predict(X_test) == y_test).mean()\n",
    "    \n",
    "    times[0] = time.time() - time_\n",
    "    time_ = time.time()\n",
    "    \n",
    "    #- GMM, 0.5*n_classes\n",
    "    svc_semisup_ensemble6 = SVCEnsemble(n_sup=200, n_semisup=200, p_inbag=0.67,\n",
    "                                        projection_kwargs={'n_components': 8},\n",
    "                                        induce=0.25, \n",
    "                                        cluster_class='gmm', cluster_kwargs={'n_components': -2},\n",
    "                                        kernel='linear',\n",
    "                                        thunder=True,\n",
    "                                        classes=classes)\n",
    "    svc_semisup_ensemble6.fit(X, y)\n",
    "    accs[1] = (svc_semisup_ensemble6.predict(X_test) == y_test).mean()\n",
    "    \n",
    "    times[1] = time.time() - time_\n",
    "    time_ = time.time()\n",
    "    \n",
    "    #- GMM, 0.5*n_classes\n",
    "    svc_semisup_ensemble6 = SVCEnsemble(n_sup=200, n_semisup=200, p_inbag=0.67,\n",
    "                                        projection_kwargs={'n_components': 8},\n",
    "                                        induce=0, \n",
    "                                        cluster_class='gmm', cluster_kwargs={'n_components': -2},\n",
    "                                        kernel='rbf',\n",
    "                                        thunder=False,\n",
    "                                        classes=classes)\n",
    "    svc_semisup_ensemble6.fit(X, y)\n",
    "    accs[2] = (svc_semisup_ensemble6.predict(X_test) == y_test).mean()\n",
    "    \n",
    "    times[2] = time.time() - time_\n",
    "    time_ = time.time()\n",
    "                                                                             \n",
    "    \n",
    "#     try:\n",
    "#         #- LDA\n",
    "#         lda = LDA()\n",
    "#         lda.fit(X[inds_sup], y[inds_sup])\n",
    "#         accs[-1] = (lda.predict(X_test) == y_test).mean()\n",
    "#     except:\n",
    "#         accs[-1] = 1 / n_classes\n",
    "    \n",
    "    return accs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "honest-power",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [02:35<15:33, 155.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72785556 0.72574444 0.7151     0.         0.         0.        ]\n",
      "[44.48121653 41.32407547 55.18655025  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [04:02<24:14, 242.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c1e194fa3cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcondensed_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom_forest_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0maccs_and_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccs_and_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccs_and_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/apu/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment=True\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "n_mc = 90\n",
    "n_cores=90\n",
    "\n",
    "props = [0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "n=100\n",
    "d=20\n",
    "c=0.5\n",
    "cc = 0.25\n",
    "n_classes=10\n",
    "\n",
    "# algorithm_indices=np.arange(5)\n",
    "accs = np.zeros((len(props), 6, n_mc))\n",
    "times = np.zeros((len(props), 6, n_mc))\n",
    "\n",
    "if run_experiment:\n",
    "    for i, p in enumerate(tqdm(props)):\n",
    "        seeds = np.random.randint(0, 10000, size=n_mc)\n",
    "        condensed_func = lambda x: random_forest_exp(n, d, n_classes, cc, c, int(n*p), x)\n",
    "\n",
    "        accs_and_times = Parallel(n_jobs=90)(delayed(condensed_func)(x) for x in seeds)\n",
    "        accs[i] = np.array([accs_and_times[i][0] for i in range(n_mc)]).T\n",
    "        times[i] = np.array([accs_and_times[i][1] for i in range(n_mc)]).T\n",
    "        \n",
    "        print(np.mean(accs[i], axis=-1))\n",
    "        print(np.mean(times[i], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "labels=['Sup', 'Semisup', \n",
    "        'Comb. (0.5)', 'Comb. (Ratio)', \n",
    "        'Comb. + Ens. (0.5)', 'Comb. + Ens. (Ratio)',\n",
    "        'Comb. + Ens. (0.5) + RP', 'Comb. + Ens. (Ratio) + RP',\n",
    "       ' LDA'\n",
    "       ]\n",
    "\n",
    "run_experiment=True\n",
    "\n",
    "if run_experiment:\n",
    "    means = np.mean(accs, axis=-1)\n",
    "    stds = np.std(accs, axis=-1) / np.sqrt(n_mc)\n",
    "\n",
    "#     pickle.dump(means, open('data/forests_meanaccs_fewshotgaussians.pkl', 'wb'))\n",
    "#     pickle.dump(stds, open('data/forests_stdaccs_fewshotgaussians.pkl', 'wb'))\n",
    "    \n",
    "else:\n",
    "#     means = pickle.load(open('data/forests_meanaccs_fewshotgaussians.pkl', 'rb'))\n",
    "#     stds = pickle.load(open('data/forests_stdaccs_fewshotgaussians.pkl', 'rb'))\n",
    "    pass\n",
    "\n",
    "for i, mean in enumerate(means.T):\n",
    "    ax.scatter(props, mean, label=labels[i])\n",
    "    ax.errorbar(props, mean, yerr=stds.T[i])\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Proportion of labeled data')\n",
    "ax.set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSupervisedSVC2(SVC):\n",
    "    def __init__(self, sC=1.0, \n",
    "                 kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        self.sup_weight=sup_weight\n",
    "        self.sup_cv_folds=sup_cv_folds\n",
    "        \n",
    "        super().__init__(C, kernel, degree, gamma, \n",
    "                 coef0, shrinking, probability,\n",
    "                 tol, cache_size, class_weight, verbose, \n",
    "                 max_iter, decision_function_shape, break_ties, random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.unlabeled_inds = np.where(y == -1)[0].astype(int)\n",
    "        self.labeled_inds = np.where(y != -1)[0].astype(int)\n",
    "        \n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if -1 in self.classes_:\n",
    "            self.classes_ = self.classes_[1:]\n",
    "                \n",
    "        self.sup_svc = self._fit_supervised(X[self.labeled_inds], y[self.labeled_inds])\n",
    "        self.semisup_svc = self._fit_semisupervised(X, y)\n",
    "        \n",
    "    \n",
    "    def _fit_supervised(self, X, y):\n",
    "        svc = SVC()\n",
    "        svc.fit(X,y)\n",
    "        return svc\n",
    "        \n",
    "        \n",
    "    def _fit_semisupervised(self, X, y):\n",
    "        n_classes = len(self.classes_)\n",
    "        labeled_inds = np.where(y != 1)[0]\n",
    "        \n",
    "        _, counts = np.unique(y[labeled_inds], return_counts=True)\n",
    "        \n",
    "        gmm = GMM(min_components=2*n_classes, max_components=2*n_classes)\n",
    "        induced_labels = gmm.fit_predict(X)\n",
    "        \n",
    "        self.labels_per_cluster = np.zeros((2*n_classes, n_classes))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            inds = np.where(y == self.classes_[i])\n",
    "            temp_induced_labels = induced_labels[inds]\n",
    "            temp_counts = np.array([len(np.where(temp_induced_labels == c)[0]) for c in range(2*n_classes)])\n",
    "            \n",
    "            self.labels_per_cluster[:, i] = temp_counts\n",
    "                    \n",
    "                    \n",
    "        svc = SVC()\n",
    "        svc.fit(X, induced_labels)\n",
    "\n",
    "        return svc\n",
    "    \n",
    "\n",
    "    def _semisup_decision_function(self, X):\n",
    "        n_induced_classes, n_classes = self.labels_per_cluster.shape\n",
    "        n_labeled = np.sum(self.labels_per_cluster)\n",
    "        dfs = self.semisup_svc.decision_function(X)\n",
    "                \n",
    "        return dfs @ self.labels_per_cluster\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "        \n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        sup_dfs = self.sup_svc.decision_function(X)\n",
    "        sup_dfs /=  np.sqrt((sup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "        \n",
    "        semisup_dfs = self._semisup_decision_function(X)\n",
    "        semisup_dfs /=  np.sqrt((semisup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "                \n",
    "        return (self.sup_weight * sup_dfs) + (1 - self.sup_weight) * semisup_dfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APU",
   "language": "python",
   "name": "apu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
