{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from rsq.samplers import *\n",
    "from rsq.samplers import _Sampler\n",
    "from rsq.helpers import set_seeds\n",
    "\n",
    "from rsq import SVCEnsemble\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def stratified_sample(y, p=0.67, replace=False):\n",
    "    unique_y, counts = np.unique(y, return_counts=True)\n",
    "    n_per_class = np.array([int(np.math.floor(p*c)) for c in counts])\n",
    "    n_per_class = np.array([max([npc, 1]) for npc in n_per_class])\n",
    "    \n",
    "    inds = [np.random.choice(np.where(y == unique_y[i])[0], size=npc, replace=replace) for i, npc in enumerate(n_per_class)]\n",
    "    \n",
    "    return np.concatenate(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Helpers\n",
    "\n",
    "def subset(X, y, n):\n",
    "    if isinstance(X, list):\n",
    "        sel = np.random.choice(X[0].shape[0], n, replace=False)\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.choice(X.shape[0], n, replace=False)\n",
    "    \n",
    "    return X[sel], y[sel]\n",
    "\n",
    "def shuffle(X, y):\n",
    "    \"\"\" shuffle X and y \"\"\"\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        sel = np.random.permutation(X[0].shape[0])\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.permutation(X.shape[0])\n",
    "    return X[sel], y[sel]\n",
    "\n",
    "def adjust_prevalance(X, y, n_pos):\n",
    "    \"\"\" adjust the prevalance of the positive class \"\"\"\n",
    "    \n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    sel = np.hstack([\n",
    "        np.random.choice(pos_idx, n_pos, replace=False),\n",
    "        neg_idx,\n",
    "    ])\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        return [x[sel] for x in X], y[sel]\n",
    "    \n",
    "    sel = np.random.permutation(sel)\n",
    "    return X[sel], y[sel]\n",
    "\n",
    "\n",
    "def process_data(X, y, n_pos_labels, n_all):\n",
    "    X, y  = shuffle(X, y)\n",
    "\n",
    "    X = [normalize(x, axis=1, norm='l2') for x in X]\n",
    "\n",
    "    X, y = subset(X, y, n=n_all)\n",
    "\n",
    "    target = np.random.choice(np.unique(y)) # !! Uniform sample class, not according to prevalance\n",
    "    y      = (y == target).astype(np.int)\n",
    "\n",
    "    X, y = adjust_prevalance(X, y, n_pos_labels)\n",
    "    \n",
    "    return X, y\n",
    "        \n",
    "def experiment(process_args, experiment_args):\n",
    "    X, y = process_data(*process_args)\n",
    "        \n",
    "    return run_exp(X, y, *experiment_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "try:\n",
    "    from thundersvm import SVC as tSVC\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "    \n",
    "class ProjectionSVC:\n",
    "    def __init__(self, projector='gaussian', projection_kwargs={},\n",
    "                 classes=None,\n",
    "                 thunder=True,\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        if projector == 'gaussian':\n",
    "            self.projector = GaussianRandomProjection\n",
    "        else:\n",
    "            self.projector=projector\n",
    "\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        self.classes_=classes\n",
    "        \n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        \n",
    "        self.thunder=thunder\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "        if -1 in self.classes_:\n",
    "            self.classes_ = self.classes_[1:]\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if self.thunder:\n",
    "            self.svc = OneVsRestClassifier(tSVC(kernel=self.kernel, C=self.C))\n",
    "        else:\n",
    "            if self.kernel == 'linear':\n",
    "                self.svc = LinearSVC(C=self.C)\n",
    "            else:\n",
    "                self.svc = SVC(kernel=self.kernel, C=self.C)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            self.svc.fit(X, y)\n",
    "        else:\n",
    "            self.projector = self.projector(**self.projection_kwargs)\n",
    "            self.projector.fit(X)\n",
    "            self.svc.fit(self.projector.transform(X), y)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        if self.projector is not None:\n",
    "            dfs = self.svc.decision_function(self.projector.transform(X))\n",
    "        else:\n",
    "            dfs = self.svc.decision_function(X)\n",
    "            \n",
    "        return dfs\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.projector is None:\n",
    "            return self.classes_[np.argmax(self.decision_function(X), axis=-1)]\n",
    "        else:\n",
    "            return self.classes_[np.argmax(self.decision_function(self.projector.transform(X)), axis=-1)]\n",
    "        \n",
    "        \n",
    "class SemiSupervisedSVC(ProjectionSVC):\n",
    "    def __init__(self, projector=None, projection_kwargs={}, \n",
    "                 classes=None, \n",
    "                 thunder=True,\n",
    "                 cluster_class='gmm', cluster_kwargs={'n_components':-2, 'covariance_type':'spherical'},\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        if cluster_class == 'gmm':\n",
    "            self.cluster_class = GaussianMixture\n",
    "        elif cluster_class == 'kmeans':\n",
    "            self.cluster_class = KMeans\n",
    "        else:\n",
    "            self.cluster_class=cluster_class\n",
    "            \n",
    "        self.cluster_kwargs=cluster_kwargs\n",
    "        \n",
    "        super().__init__(projector, projection_kwargs, classes, thunder, C, kernel, degree, gamma, \n",
    "                 coef0, shrinking, probability,\n",
    "                 tol, cache_size, class_weight, verbose, \n",
    "                 max_iter, decision_function_shape, break_ties, random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, y_induced=None):\n",
    "        self.unlabeled_inds = np.where(y == -1)[0].astype(int)\n",
    "        self.labeled_inds = np.where(y != -1)[0].astype(int)\n",
    "        \n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "            if -1 in self.classes_:\n",
    "                self.classes_ = self.classes_[1:]\n",
    "\n",
    "        \n",
    "        n_classes = len(self.classes_)        \n",
    "        if y_induced is None:\n",
    "            if 'n_components' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_components'] < 0:\n",
    "                    self.cluster_kwargs['n_components'] *= -1\n",
    "                    self.cluster_kwargs['n_components'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_components'] = int(self.cluster_kwargs['n_components'])\n",
    "                self.n_components=self.cluster_kwargs['n_components']\n",
    "            elif 'n_clusters' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_clusters'] < 0:\n",
    "                    self.cluster_kwargs['n_clusters'] *= -1\n",
    "                    self.cluster_kwargs['n_clusters'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_clusters'] = int(self.cluster_kwargs['n_clusters'])\n",
    "                self.n_components=self.cluster_kwargs['n_clusters']\n",
    "            else:\n",
    "                raise ValueError('keyword n_components or n_clusters must be present in cluster_kwargs')\n",
    "        else:\n",
    "            self.n_components = len(np.unique(y_induced))\n",
    "            \n",
    "                \n",
    "        if y_induced is None:\n",
    "            cluster_instance = self.cluster_class(**self.cluster_kwargs)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            if y_induced is None:\n",
    "                y_induced = cluster_instance.fit_predict(X)\n",
    "        else:\n",
    "            self.projector = self.projector(**self.projection_kwargs) \n",
    "            self.projector.fit(X)\n",
    "            if y_induced is None:\n",
    "                y_induced = cluster_instance.fit_predict(self.projector.transform(X))\n",
    "         \n",
    "        self.labels_per_cluster = np.zeros((self.n_components, n_classes))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            inds = np.where(y == self.classes_[i])\n",
    "            temp_y_induced = y_induced[inds]\n",
    "            temp_counts = np.array([len(np.where(temp_y_induced == c)[0]) for c in range(self.n_components)])\n",
    "            \n",
    "            self.labels_per_cluster[:, i] = temp_counts\n",
    " \n",
    "        \n",
    "        if self.thunder:\n",
    "            self.svc = OneVsRestClassifier(tSVC(kernel=self.kernel, C=self.C))\n",
    "        else:\n",
    "            if self.kernel == 'linear':\n",
    "                self.svc = LinearSVC(C=self.C)\n",
    "            else:\n",
    "                self.svc = SVC(kernel=self.kernel, C=self.C)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            self.svc.fit(X, y_induced)\n",
    "        else:\n",
    "            self.svc.fit(self.projector.transform(X), y_induced)\n",
    "    \n",
    "\n",
    "    def decision_function(self, X):\n",
    "        n_labeled = np.sum(self.labels_per_cluster)\n",
    "        \n",
    "        if self.projector is None:\n",
    "            dfs = self.svc.decision_function(X)\n",
    "        else:\n",
    "            dfs = self.svc.decision_function(self.projector.transform(X))\n",
    "            \n",
    "        return dfs @ self.labels_per_cluster\n",
    "            \n",
    "\n",
    "class SVCEnsemble:\n",
    "    def __init__(self, n_sup=1, n_semisup=1, sup_weight=None, \n",
    "                 p_inbag=1, \n",
    "                 projector=None, projection_kwargs={},\n",
    "                 classes=None, n_jobs=1,\n",
    "                 thunder=False, \n",
    "                 induce=0, cluster_class='gmm', cluster_kwargs={'n_components':-2, 'covariance_type':'spherical'},\n",
    "                 C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "                 coef0=0.0, shrinking=True, probability=False,\n",
    "                 tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None):\n",
    "        \n",
    "        self.induce=induce\n",
    "        self.n_sup=n_sup\n",
    "        self.n_semisup = n_semisup\n",
    "        self.sup_weight=sup_weight\n",
    "\n",
    "        self.p_inbag=p_inbag\n",
    "        \n",
    "        self.classes_ = classes\n",
    "        self.n_jobs=n_jobs\n",
    "        \n",
    "        if projector is \"gaussian\":\n",
    "            self.projector=GaussianRandomProjection\n",
    "        else:\n",
    "            self.projector=projector\n",
    "\n",
    "        self.projection_kwargs=projection_kwargs\n",
    "        \n",
    "        if cluster_class == 'gmm':\n",
    "            self.cluster_class = GaussianMixture\n",
    "        elif cluster_class == 'kmeans':\n",
    "            self.cluster_class = KMeans\n",
    "            \n",
    "        self.cluster_kwargs=cluster_kwargs\n",
    "        \n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        \n",
    "        self.thunder=thunder\n",
    "            \n",
    "        self.ensemble = []\n",
    "                \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.unlabeled_inds = np.where(y == -1)[0].astype(int)\n",
    "        self.labeled_inds = np.where(y != -1)[0].astype(int)\n",
    "        \n",
    "        if self.sup_weight is None:\n",
    "            self.sup_weight = len(self.labeled_inds) / (len(self.labeled_inds) + len(self.unlabeled_inds))\n",
    "        \n",
    "        if self.classes_ is None:\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "            if -1 in self.classes_:\n",
    "                self.classes_ = self.classes_[1:]\n",
    "                \n",
    "        if self.induce > 0 and self.n_semisup > 0:\n",
    "            if 'n_components' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_components'] < 0:\n",
    "                    self.cluster_kwargs['n_components'] *= -1\n",
    "                    self.cluster_kwargs['n_components'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_components'] = int(self.cluster_kwargs['n_components'])\n",
    "                self.n_components=self.cluster_kwargs['n_components']\n",
    "            elif 'n_clusters' in list(self.cluster_kwargs.keys()):\n",
    "                if self.cluster_kwargs['n_clusters'] < 0:\n",
    "                    self.cluster_kwargs['n_clusters'] *= -1\n",
    "                    self.cluster_kwargs['n_clusters'] *= len(self.classes_)\n",
    "                    self.cluster_kwargs['n_clusters'] = int(self.cluster_kwargs['n_clusters'])\n",
    "                self.n_components=self.cluster_kwargs['n_clusters']\n",
    "            else:\n",
    "                raise ValueError('keyword n_components must be present in cluster_kwargs')\n",
    "            \n",
    "            cluster_instance = self.cluster_class(**self.cluster_kwargs)\n",
    "            self.y_induced=cluster_instance.fit_predict(X)\n",
    "        else:\n",
    "            self.y_induced=None\n",
    "                                \n",
    "        condensed_func = lambda x: self._train_svc(X, y, x, stratified=True)\n",
    "        func_tuples = np.concatenate((np.ones(self.n_sup), np.zeros(self.n_semisup))).astype(int)\n",
    "                \n",
    "        self.ensemble = Parallel(n_jobs=self.n_jobs)(delayed(condensed_func)(tuple_) for tuple_ in func_tuples)\n",
    "            \n",
    "    def _train_svc(self, X, y, supervised=True, stratified=True):                \n",
    "        if len(self.labeled_inds) == len(y):\n",
    "            all_supervised=True\n",
    "        else:\n",
    "            all_supervised=False\n",
    "\n",
    "        if self.p_inbag >= 1:\n",
    "            self.p_inbag=1\n",
    "            replace=False\n",
    "        else:\n",
    "            replace=True\n",
    "                        \n",
    "        if supervised:\n",
    "            bag_inds = stratified_sample(y[self.labeled_inds], p=self.p_inbag, replace=False)\n",
    "            svc = ProjectionSVC(projector=self.projector, projection_kwargs=self.projection_kwargs, \n",
    "                                thunder=self.thunder, classes=self.classes_, kernel=self.kernel, C=self.C)\n",
    "            svc.fit(X[self.labeled_inds[bag_inds]], y[self.labeled_inds[bag_inds]])\n",
    "            \n",
    "        else:\n",
    "            sbag_inds = stratified_sample(y[self.labeled_inds], p=self.p_inbag, replace=False)\n",
    "            if all_supervised:\n",
    "                bag_inds = sbag_inds\n",
    "            else:\n",
    "                ssbag_inds = np.random.choice(len(self.unlabeled_inds), size=int(X.shape[0]*0.67), replace=True)\n",
    "                bag_inds = np.concatenate((self.labeled_inds[sbag_inds], ssbag_inds))\n",
    "            \n",
    "            svc = SemiSupervisedSVC(projector=self.projector, projection_kwargs=self.projection_kwargs, \n",
    "                                    classes=self.classes_,\n",
    "                                    thunder=self.thunder,\n",
    "                                   cluster_class=self.cluster_class, cluster_kwargs=self.cluster_kwargs,\n",
    "                                    kernel=self.kernel, C=self.C)\n",
    "\n",
    "            use_pre_induced=np.random.binomial(1, self.induce)\n",
    "            if use_pre_induced:\n",
    "                svc.fit(X[bag_inds], y[bag_inds], self.y_induced[bag_inds])\n",
    "            else:\n",
    "                svc.fit(X[bag_inds], y[bag_inds])\n",
    "                    \n",
    "                \n",
    "        return svc\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        if self.n_sup > 0:\n",
    "            # Play around with different normalization \n",
    "            sup_dfs = np.sum([svc.decision_function(X) for svc in self.ensemble[:self.n_sup]], axis=0)\n",
    "            sup_dfs /= np.sqrt((sup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "        else:\n",
    "            sup_dfs = 0\n",
    "        \n",
    "\n",
    "        if self.n_semisup > 0:    \n",
    "            semisup_dfs = np.sum([svc.decision_function(X) for svc in self.ensemble[self.n_sup:]], axis=0)\n",
    "            semisup_dfs /= np.sqrt((semisup_dfs ** 2).sum(axis=-1, keepdims=True))\n",
    "        else:\n",
    "            semisup_dfs = 0\n",
    "\n",
    "        # Play around w voting instead of averaging scores\n",
    "        return (self.sup_weight * sup_dfs) + ((1 - self.sup_weight) * semisup_dfs)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.decision_function(X)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.decision_function(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32682, 2048) 32682 500 29 68.0 83\n"
     ]
    }
   ],
   "source": [
    "# --\n",
    "# Experiment parameters & initial data loading\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "data_files = ['../output/feats/crow_resnet50/birdsnap/'\n",
    "             ]\n",
    "models = [s.split('/')[-3] for s in data_files]\n",
    "\n",
    "\n",
    "X = [np.load(os.path.join(f, 'X.npy')).astype(np.float64) for f in data_files][0]\n",
    "y_str = np.load(os.path.join(data_files[0], 'y.npy'))\n",
    "classes_str, class_counts= np.unique(y_str, return_counts=True)\n",
    "y=np.zeros(len(y_str))\n",
    "for i, str_ in enumerate(classes_str):\n",
    "    y[np.where(y_str == str_)[0]] = i\n",
    "\n",
    "y = y.astype(int)\n",
    "classes=np.unique(y)\n",
    "\n",
    "print(X.shape, len(y), len(classes), np.min(class_counts), np.median(class_counts), np.max(class_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_exp(X, y, p=0.1, acorn=None):\n",
    "    X = X.copy() / np.sqrt((X.copy() ** 2).sum(axis=-1, keepdims=True))\n",
    "    \n",
    "    inds_sup = stratified_sample(y, p, replace=False)\n",
    "    inds_unsup = np.array([i for i in range(len(y)) if i not in inds_sup]).astype(int)\n",
    "\n",
    "    y_ = -1 * np.ones(n)\n",
    "    y_[inds_sup] = y[inds_sup]\n",
    "    \n",
    "    #- 2 = Supervised, Semisupervised\n",
    "    accs = np.zeros(2)\n",
    "    times = np.zeros(2)\n",
    "        \n",
    "    print(\"begin fit1\")\n",
    "    time_ = time()\n",
    "    \n",
    "    #- Supervised\n",
    "    svc_sup = LinearSVC(C=1)\n",
    "    svc_sup.fit(X[inds_sup], y[inds_sup])\n",
    "    accs[0] = (svc_sup.predict(X[inds_unsup]) == y[inds_unsup]).mean()\n",
    "    times[0] = time() - time_\n",
    "    \n",
    "    print(\"begin fit2\")\n",
    "    #- Semi-Supervised\n",
    "    svc_semisup = SVCEnsemble(n_sup=500, n_semisup=0, p_inbag=1, sup_weight=0.5,\n",
    "                              thunder=False,\n",
    "                              cluster_class='kmeans', cluster_kwargs={'n_clusters': -3, 'n_jobs': 3},\n",
    "                              n_jobs=9,\n",
    "                              projector='gaussian', projection_kwargs={'n_components': 64},\n",
    "                              induce=1, classes=classes, kernel='linear')\n",
    "#     svc_semisup = ProjectionSVC(projector=None, classes=classes, kernel='linear', thunder=False)\n",
    "    svc_semisup.fit(X[inds_sup], y[inds_sup])\n",
    "    accs[1] = (svc_semisup.predict(X[inds_unsup]) == y[inds_unsup]).mean()\n",
    "    times[1] = time() - time_\n",
    "    time_ = time()\n",
    "    \n",
    "    return accs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "finished in 7540.4\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "prop_labeled=[0.2, 0.3, 0.5, 0.8]\n",
    "n_cores=10\n",
    "# n_mc=int(n_cores / len(prop_labeled))\n",
    "n_mc=10\n",
    "\n",
    "experiment_tuples = []\n",
    "\n",
    "for i, p in enumerate(prop_labeled):\n",
    "    for _ in range(n_mc):\n",
    "        all_inds = stratified_sample(y, p=0.5, replace=False)\n",
    "        n=len(all_inds)\n",
    "        \n",
    "        experiment_tuples.append((X[all_inds], y[all_inds], p))\n",
    "    \n",
    "\n",
    "condensed_func = lambda x: svc_exp(*x)\n",
    "start_time = time()\n",
    "print(len(experiment_tuples))\n",
    "try:\n",
    "    accuracies_and_times = Parallel(n_jobs=n_cores)(delayed(condensed_func)(tupl) for tupl in experiment_tuples)\n",
    "    print(\"finished in %1.1f\"%(time() - start_time))\n",
    "except:\n",
    "    print(\"error after %1.1f\"%(time() - start_time))\n",
    "    assert 0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.zeros((len(prop_labeled), 2, n_mc))\n",
    "times = np.zeros((len(prop_labeled), 2, n_mc))\n",
    "\n",
    "for i in range(len(prop_labeled)):\n",
    "    for j in range(n_mc):\n",
    "        temp = accuracies_and_times[i*len(prop_labeled) + j]\n",
    "        accuracies[i,:, j] = temp[0]\n",
    "        times[i,:, j] = temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff3788a7710>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "algos = ['SVC', 'SVC + RPs']\n",
    "\n",
    "for i, algo in enumerate(algos):\n",
    "    ax.scatter(prop_labeled, np.mean(accuracies, axis=-1)[:, i], label=algo)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "X_, y_ = experiment_tuples[0][:-1]\n",
    "inds = stratified_sample(y_, p=0.1)\n",
    "y__ = -1 * np.ones(len(y_))\n",
    "y__[inds] = y_[inds]\n",
    "print(len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train linear SVC: 11.246625185012817 0.2704837117472853\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC(C=1)\n",
    "time_ = time()\n",
    "linear_svc.fit(X_[inds], y__[inds])\n",
    "\n",
    "print(\"time to train linear SVC:\", time() - time_, (linear_svc.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train linear SVC: 5.599503040313721 0.28298782494241526\n"
     ]
    }
   ],
   "source": [
    "# linear_svc_ensemble = ProjectionSVC(projector=None, kernel='linear', thunder=False)\n",
    "linear_svc_ensemble = SVCEnsemble(n_sup=200, n_semisup=0, sup_weight=0.5, p_inbag=1, \n",
    "                         thunder=False, projector='gaussian', projection_kwargs={'n_components': 64},\n",
    "                                  n_jobs=20,\n",
    "                        kernel='linear', C=1, cluster_kwargs={'n_components':-2})\n",
    "time_ = time()\n",
    "linear_svc_ensemble.fit(X_, y__)\n",
    "print(\"time to train linear SVC:\", time() - time_,  (linear_svc_ensemble.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train linear SVC: 136.1855399608612 0.2681803224744982\n"
     ]
    }
   ],
   "source": [
    "# linear_svc_ensemble = ProjectionSVC(projector=None, kernel='linear', thunder=False)\n",
    "linear_svc_ensemble = SVCEnsemble(n_sup=100, n_semisup=100, sup_weight=0.5, p_inbag=1,\n",
    "                                  induce=0,\n",
    "                         thunder=False, projector='gaussian', projection_kwargs={'n_components': 64},\n",
    "                                  n_jobs=20,\n",
    "                        kernel='linear', C=1, cluster_kwargs={'n_components':-3})\n",
    "time_ = time()\n",
    "linear_svc_ensemble.fit(X_, y__)\n",
    "print(\"time to train linear SVC:\", time() - time_,  (linear_svc_ensemble.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.22244159262915433\n",
      "0.1 0.23132609410990457\n",
      "0.2 0.2418558736426456\n",
      "0.3 0.25074037512339586\n",
      "0.4 0.2592958209937479\n",
      "0.5 0.2681803224744982\n",
      "0.6 0.2754195459032576\n",
      "0.7 0.2783810463968411\n",
      "0.8 0.28068443566962814\n",
      "0.9 0.28298782494241526\n",
      "1.0 0.2836459361632116\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(11):\n",
    "    linear_svc_ensemble.sup_weight=i/10\n",
    "    print(i/10, (linear_svc_ensemble.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train linear SVC: 215.69433736801147 0.4257979598552155\n"
     ]
    }
   ],
   "source": [
    "# linear_svc_ensemble = ProjectionSVC(projector=None, kernel='linear', thunder=False)\n",
    "linear_svc_ensemble = SVCEnsemble(n_sup=200, n_semisup=200, sup_weight=0.5, p_inbag=1,\n",
    "                                  induce=0,\n",
    "                         thunder=False, projector='gaussian', projection_kwargs={'n_components': 64},\n",
    "                                  n_jobs=20,\n",
    "                        kernel='linear', C=1, cluster_kwargs={'n_components':-2})\n",
    "time_ = time()\n",
    "linear_svc_ensemble.fit(X_, y__)\n",
    "print(\"time to train linear SVC:\", time() - time_,  (linear_svc_ensemble.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24086870681145114\n",
      "0.3142481079302402\n",
      "0.35867061533399147\n",
      "0.38631128660743663\n",
      "0.40638367884172427\n",
      "0.4257979598552155\n",
      "0.4442250740375123\n",
      "0.45475485357025336\n",
      "0.462323132609411\n",
      "0.466600855544587\n",
      "0.4662717999341889\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(11):\n",
    "    linear_svc_ensemble.sup_weight=i/10\n",
    "    print((linear_svc_ensemble.predict(X_) == y_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train linear SVC: 26.94737458229065 0.4652846331029944\n"
     ]
    }
   ],
   "source": [
    "# linear_svc_ensemble = ProjectionSVC(projector=None, kernel='linear', thunder=False)\n",
    "linear_svc_ensemble2 = SVCEnsemble(n_sup=400, n_semisup=0, sup_weight=0.5, p_inbag=1,\n",
    "                                  induce=0,\n",
    "                         thunder=False, projector='gaussian', projection_kwargs={'n_components': 64},\n",
    "                                  n_jobs=20,\n",
    "                        kernel='linear', C=1, cluster_kwargs={'n_components':-2})\n",
    "time_ = time()\n",
    "linear_svc_ensemble2.fit(X_, y__)\n",
    "print(\"time to train linear SVC:\", time() - time_,  (linear_svc_ensemble2.predict(X_) == y_).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APU",
   "language": "python",
   "name": "apu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
